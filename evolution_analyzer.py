"""
åŒ»å°ç®¡è‡ªæˆ‘è¿›åŒ–åˆ†æè„šæœ¬
æ¯å‘¨è¿è¡Œä¸€æ¬¡ï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®æ¸…å•
"""

import pandas as pd
import jieba
from collections import Counter
from datetime import datetime, timedelta
import os

class EvolutionAnalyzer:
    def __init__(self, log_file="evolution_logs.csv"):
        self.log_file = log_file
        self.df = None
        
    def load_data(self):
        """åŠ è½½æ—¥å¿—æ•°æ®"""
        if not os.path.exists(self.log_file):
            print("âŒ æš‚æ— æ—¥å¿—æ•°æ®")
            return False
        
        self.df = pd.read_csv(self.log_file)
        print(f"âœ… åŠ è½½äº† {len(self.df)} æ¡å¯¹è¯è®°å½•")
        return True
    
    def analyze_high_frequency_questions(self, top_n=20):
        """åˆ†æé«˜é¢‘é—®é¢˜å…³é”®è¯"""
        if self.df is None or len(self.df) == 0:
            return []
        
        questions = self.df['é—®é¢˜'].tolist()
        words = []
        for q in questions:
            # ä½¿ç”¨jiebaåˆ†è¯
            words.extend(jieba.lcut(str(q)))
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = ['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'å—', 
                      'å‘¢', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä»€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å“ªä¸ª', 
                      'å¯ä»¥', 'éœ€è¦', 'ç”³è¯·', 'åŠç†']
        filtered_words = [w for w in words if len(w) > 1 and w not in stop_words]
        
        word_count = Counter(filtered_words)
        top_words = word_count.most_common(top_n)
        
        print(f"\nğŸ”¥ é«˜é¢‘å…³é”®è¯ TOP{top_n}ï¼š")
        for word, count in top_words:
            print(f"  {word}: {count}æ¬¡")
        
        return top_words
    
    def analyze_response_quality(self):
        """åˆ†æå›ç­”è´¨é‡"""
        if self.df is None:
            return {}
        
        quality_stats = {}
        
        # å¹³å‡å›ç­”é•¿åº¦
        if 'å›ç­”é•¿åº¦' in self.df.columns:
            quality_stats['avg_response_length'] = self.df['å›ç­”é•¿åº¦'].mean()
        
        # å¹³å‡æ¥æºæ•°é‡
        if 'æ¥æºæ•°é‡' in self.df.columns:
            quality_stats['avg_sources'] = self.df['æ¥æºæ•°é‡'].mean()
        
        # æ— æ¥æºå›ç­”æ¯”ä¾‹
        if 'æ¥æºæ•°é‡' in self.df.columns:
            no_source_pct = (self.df['æ¥æºæ•°é‡'] == 0).mean() * 100
            quality_stats['no_source_pct'] = no_source_pct
        
        # ç”¨æˆ·åé¦ˆç»Ÿè®¡
        if 'ç”¨æˆ·åé¦ˆ' in self.df.columns:
            like_count = (self.df['ç”¨æˆ·åé¦ˆ'] == 'like').sum()
            dislike_count = (self.df['ç”¨æˆ·åé¦ˆ'] == 'dislike').sum()
            total_feedback = like_count + dislike_count
            
            quality_stats['like_count'] = like_count
            quality_stats['dislike_count'] = dislike_count
            if total_feedback > 0:
                quality_stats['satisfaction_rate'] = like_count / total_feedback * 100
            else:
                quality_stats['satisfaction_rate'] = 0
        
        return quality_stats
    
    def analyze_bad_responses(self):
        """åˆ†æç”¨æˆ·ç‚¹è¸©çš„é—®é¢˜"""
        if self.df is None:
            return []
        
        bad_df = self.df[self.df['ç”¨æˆ·åé¦ˆ'] == 'dislike']
        
        if len(bad_df) == 0:
            print("\nğŸ‘ æš‚æ— ç‚¹è¸©è®°å½•ï¼Œç»§ç»­ä¿æŒï¼")
            return []
        
        print(f"\nğŸ‘ ç”¨æˆ·ç‚¹è¸©çš„é—®é¢˜ï¼ˆ{len(bad_df)}æ¡ï¼‰ï¼š")
        bad_questions = []
        for _, row in bad_df.iterrows():
            print(f"  é—®é¢˜: {row['é—®é¢˜']}")
            print(f"  æ—¶é—´: {row['æ—¶é—´']}")
            bad_questions.append(row['é—®é¢˜'])
        
        return bad_questions
    
    def analyze_no_source_responses(self):
        """åˆ†ææ²¡æœ‰æ¥æºçš„å›ç­”"""
        if self.df is None:
            return []
        
        if 'æ¥æºæ•°é‡' not in self.df.columns:
            return []
        
        no_source_df = self.df[self.df['æ¥æºæ•°é‡'] == 0]
        
        if len(no_source_df) == 0:
            print("\nğŸ“š æ‰€æœ‰å›ç­”éƒ½æœ‰æ¥æºï¼Œå¾ˆæ£’ï¼")
            return []
        
        print(f"\nğŸ“š éœ€è¦è¡¥å……çŸ¥è¯†åº“çš„é—®é¢˜ï¼ˆ{len(no_source_df)}æ¡ï¼‰ï¼š")
        questions = []
        for _, row in no_source_df.head(10).iterrows():
            print(f"  é—®é¢˜: {row['é—®é¢˜']}")
            questions.append(row['é—®é¢˜'])
        
        return questions
    
    def analyze_performance(self):
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        if self.df is None:
            return {}
        
        perf_stats = {}
        
        if 'å“åº”æ—¶é—´(ms)' in self.df.columns:
            perf_stats['avg_response_time'] = self.df['å“åº”æ—¶é—´(ms)'].mean()
            perf_stats['max_response_time'] = self.df['å“åº”æ—¶é—´(ms)'].max()
            perf_stats['p95_response_time'] = self.df['å“åº”æ—¶é—´(ms)'].quantile(0.95)
        
        return perf_stats
    
    def generate_optimization_todo(self):
        """ç”ŸæˆçŸ¥è¯†åº“ä¼˜åŒ–å¾…åŠæ¸…å•"""
        if not self.load_data():
            return
        
        suggestions = []
        
        # 1. è´¨é‡åˆ†æ
        quality = self.analyze_response_quality()
        if quality:
            suggestions.append(f"## è´¨é‡æŠ¥å‘Š")
            suggestions.append(f"- å¹³å‡å›ç­”é•¿åº¦: {quality.get('avg_response_length', 0):.1f}å­—")
            suggestions.append(f"- å¹³å‡æ¥æºæ•°é‡: {quality.get('avg_sources', 0):.1f}æ¡")
            suggestions.append(f"- æ— æ¥æºå›ç­”æ¯”ä¾‹: {quality.get('no_source_pct', 0):.1f}%")
            suggestions.append(f"- ç”¨æˆ·æ»¡æ„åº¦: {quality.get('satisfaction_rate', 0):.1f}%")
            suggestions.append("")
        
        # 2. é«˜é¢‘è¯å»ºè®®
        top_words = self.analyze_high_frequency_questions(top_n=10)
        if top_words:
            suggestions.append(f"## é«˜é¢‘å…³é”®è¯ï¼ˆå¯èƒ½ç¼ºå¤±çš„çŸ¥è¯†ï¼‰")
            for word, count in top_words:
                if count > 3:
                    suggestions.append(f"- [ ] éœ€è¦è¡¥å……å…³äºã€Œ{word}ã€çš„çŸ¥è¯†æ–‡æ¡£ï¼ˆå‡ºç°{count}æ¬¡ï¼‰")
            suggestions.append("")
        
        # 3. ç‚¹è¸©é—®é¢˜
        bad_questions = self.analyze_bad_responses()
        if bad_questions:
            suggestions.append(f"## éœ€è¦ä¼˜åŒ–çš„å›ç­”")
            for q in bad_questions[:5]:
                suggestions.append(f"- [ ] ä¼˜åŒ–å›ç­”: {q[:50]}...")
            suggestions.append("")
        
        # 4. æ— æ¥æºé—®é¢˜
        no_source = self.analyze_no_source_responses()
        if no_source:
            suggestions.append(f"## éœ€è¦è¡¥å……çŸ¥è¯†åº“çš„é—®é¢˜")
            for q in no_source[:5]:
                suggestions.append(f"- [ ] è¡¥å……çŸ¥è¯†: {q[:50]}...")
            suggestions.append("")
        
        # 5. æ€§èƒ½åˆ†æ
        perf = self.analyze_performance()
        if perf:
            suggestions.append(f"## æ€§èƒ½æŠ¥å‘Š")
            suggestions.append(f"- å¹³å‡å“åº”æ—¶é—´: {perf.get('avg_response_time', 0):.0f}ms")
            suggestions.append(f"- 95åˆ†ä½å“åº”æ—¶é—´: {perf.get('p95_response_time', 0):.0f}ms")
            if perf.get('p95_response_time', 0) > 5000:
                suggestions.append(f"- [ ] å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–çŸ¥è¯†åº“æ£€ç´¢")
        
        # ç”ŸæˆMarkdownæ ¼å¼çš„å¾…åŠæ¸…å•
        filename = f"kb_optimization_{datetime.now().strftime('%Y%m%d')}.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ“š åŒ»å°ç®¡çŸ¥è¯†åº“ä¼˜åŒ–æ¸…å•\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
            for s in suggestions:
                f.write(f"{s}\n")
        
        print(f"\nâœ… å·²ç”Ÿæˆä¼˜åŒ–æ¸…å•ï¼š{filename}")
        return suggestions


def main():
    print("="*60)
    print("ğŸ§¬ åŒ»å°ç®¡è‡ªæˆ‘è¿›åŒ–åˆ†æç³»ç»Ÿ v2.0")
    print("="*60)
    
    analyzer = EvolutionAnalyzer()
    
    # ç”Ÿæˆä¼˜åŒ–æ¸…å•
    analyzer.generate_optimization_todo()
    
    # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
    if analyzer.df is not None:
        print("\nğŸ“Š ç®€è¦ç»Ÿè®¡ï¼š")
        print(f"æ€»å¯¹è¯æ•°: {len(analyzer.df)}")
        
        # æŒ‰æ—¥æœŸç»Ÿè®¡
        if 'æ—¶é—´' in analyzer.df.columns:
            analyzer.df['æ—¥æœŸ'] = pd.to_datetime(analyzer.df['æ—¶é—´']).dt.date
            daily = analyzer.df.groupby('æ—¥æœŸ').size()
            print(f"æ—¥å‡å¯¹è¯: {daily.mean():.1f}æ¡")


if __name__ == "__main__":
    main()